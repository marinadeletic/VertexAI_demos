{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff16c5e1",
   "metadata": {},
   "source": [
    "# Classification Model using BQML deploying to Vertex AI (Manual) \n",
    "This notebook will walk through the creation process of a BQML classification model for marketing data on the new Vertex Managed Notebooks. The classification goal is to predict if the client targeted by a marketing campaign will subscribe to a new finanical product (variable y).\n",
    "\n",
    "[Data Source](https://archive.ics.uci.edu/ml/datasets/bank+marketing#)\n",
    " | [Raw Data: bank-additional](https://archive.ics.uci.edu/ml/machine-learning-databases/00222/) \n",
    " | * Note: change column name 'default' - special BQ statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a430b7",
   "metadata": {},
   "source": [
    "## Environment Set up\n",
    "This demo uses ecommerce Google Analytics data, publicly available as a BigQuery dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b22e809d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = 'sandbox-marina' #replace value\n",
    "LOCATION = 'us-central1'\n",
    "DATASET_NAME= 'marketing_bank'\n",
    "MODEL_NAME= 'cl_model_willbuy'\n",
    "\n",
    "BUCKET_NAME = f'{PROJECT_ID}_{MODEL_NAME}' ## or replace with string of bucket name already created \n",
    "DATASET_ID = f'{PROJECT_ID}.{DATASET_NAME}'## or replace with dataset already created "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec6c267",
   "metadata": {},
   "source": [
    "### Create Bucket and Dataset \n",
    "*(If you haven't already)*\n",
    "\n",
    "**Create New Bucket**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0dbf8e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "\n",
    "storage_client = storage.Client()\n",
    "bucket = storage_client.bucket(BUCKET_NAME)\n",
    "new_bucket = storage_client.create_bucket(bucket, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151ce793",
   "metadata": {},
   "source": [
    "**Create Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea15c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "client = bigquery.Client()\n",
    "dataset = bigquery.Dataset(DATASET_ID)\n",
    "dataset.location = \"US\"\n",
    "dataset = client.create_dataset(dataset, timeout=30) \n",
    "\n",
    "print(\"Created dataset {}.{}\".format(client.project, dataset.dataset_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0f24c4",
   "metadata": {},
   "source": [
    "## Explore Data\n",
    "Preview Data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d6561e",
   "metadata": {},
   "source": [
    "#@bigquery\n",
    "SELECT * \n",
    "FROM `marketing_bank.training` LIMIT 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f5d711",
   "metadata": {},
   "source": [
    "What is our conversion rate? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0da37c",
   "metadata": {},
   "source": [
    "#@bigquery\n",
    "SELECT\n",
    "  COUNT(y) AS total_target_market,\n",
    "  COUNTIF(y is TRUE) AS total_purchasers,\n",
    "  ROUND( COUNTIF(y is TRUE) / COUNT(y),2) AS conversion_rate\n",
    "FROM\n",
    "    `marketing_bank.training` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb06fce6",
   "metadata": {},
   "source": [
    "## Create BQML Classification Model\n",
    "Predict if targeted individual \"will subscribe\" or \"won't subscribe\", using logistic_reg in a classification model. Replace your model destination and name if needed.\n",
    "\n",
    "* We use TRANSFORM in the model defenition to automatically apply any tranformations during prediction and evaluation. \n",
    "* We have used FEATURE_CROSS to create a feature cross of if the indiviual has a house and a loan. \n",
    "* model type is `logistic_reg` as we have a binary classification problem\n",
    "* To implement explainability at a model level we set ENABLE_GLOBAL_EXPLAIN to True \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a348b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'marketing_bank.cl_model_willbuy'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Name \n",
    "f'{DATASET_NAME}.{MODEL_NAME}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb31b75b",
   "metadata": {},
   "source": [
    "#@bigquery\n",
    "CREATE OR REPLACE MODEL `marketing_bank.cl_model_willbuy`\n",
    "TRANSFORM(\n",
    "    ML.FEATURE_CROSS(STRUCT(housing,loan)) AS house_loan,\n",
    "    ML.FEATURE_CROSS(STRUCT(month,day_of_week)) AS day_month, *\n",
    ")\n",
    "OPTIONS(\n",
    "    model_type='logistic_reg',\n",
    "    labels = ['y'],\n",
    "    ENABLE_GLOBAL_EXPLAIN = True\n",
    "    )\n",
    "AS \n",
    "SELECT * \n",
    "FROM `marketing_bank.training`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22f2085",
   "metadata": {},
   "source": [
    "## Evaluation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397254f1",
   "metadata": {},
   "source": [
    "#@bigquery\n",
    "#@bigquery\n",
    "SELECT * FROM \n",
    "ML.EVALUATE (MODEL marketing_bank.cl_model_willbuy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaad01ea",
   "metadata": {},
   "source": [
    "## Explain Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf25012",
   "metadata": {},
   "source": [
    "#@bigquery\n",
    "SELECT * \n",
    "FROM ML.GLOBAL_EXPLAIN(MODEL marketing_bank.cl_model_willbuy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5432e1c8",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ab8664",
   "metadata": {},
   "source": [
    "#@bigquery\n",
    "\n",
    "SELECT\n",
    "  *\n",
    "FROM \n",
    "\tML.EXPLAIN_PREDICT( MODEL `marketing_bank.cl_model_willbuy`,\n",
    "    (\n",
    "    SELECT *\n",
    "    FROM\n",
    "      `marketing_bank.test`),\n",
    "    STRUCT(0.2 AS threshold))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a766988",
   "metadata": {},
   "source": [
    "# Export Model to Vertex AI \n",
    "While being able to TRANSFORM features in BQ is great, this featyure is not supported by the export functionality. So we will re-run with out adding additional features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d01619",
   "metadata": {},
   "source": [
    "#@bigquery\n",
    "CREATE OR REPLACE MODEL `marketing_bank.cl_model_willbuy`\n",
    "OPTIONS(\n",
    "    model_type='logistic_reg',\n",
    "    labels = ['y'],\n",
    "    ENABLE_GLOBAL_EXPLAIN = True\n",
    "    )\n",
    "AS \n",
    "SELECT * \n",
    "FROM `marketing_bank.training` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28c8684",
   "metadata": {},
   "source": [
    "**Export to GCS then upload to Vertex AI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aeb9b228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting on bqjob_r2c8a72a3935ddc25_0000017c158ff537_1 ... (22s) Current status: DONE   \n"
     ]
    }
   ],
   "source": [
    "!bq extract -m {PROJECT_ID}:{DATASET_NAME}.{MODEL_NAME} gs://{BUCKET_NAME}/{MODEL_NAME}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5872298b",
   "metadata": {},
   "source": [
    "**Upload model to Vertex**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7971b76",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'aiplatform' from 'google.cloud' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-099fba7dc065>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcloud\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maiplatform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0maiplatform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPROJECT_ID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLOCATION\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m model = aiplatform.Model.upload(\n\u001b[1;32m      4\u001b[0m         \u001b[0mdisplay_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMODEL_NAME\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0martifact_uri\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34mf'gs://{BUCKET_NAME}/{MODEL_NAME}'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'aiplatform' from 'google.cloud' (unknown location)"
     ]
    }
   ],
   "source": [
    "from google.cloud import aiplatform\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION)\n",
    "model = aiplatform.Model.upload(\n",
    "        display_name=MODEL_NAME,\n",
    "        artifact_uri= f'gs://{BUCKET_NAME}/{MODEL_NAME}',\n",
    "        serving_container_image_uri='us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-3:latest' ) \n",
    "model.wait()\n",
    "\n",
    "print(model.display_name)\n",
    "print(model.resource_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05dc1e05",
   "metadata": {},
   "source": [
    "**Deploy to an endpoint**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168e16c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = aiplatform.Endpoint.create( display_name=f'{MODEL_NAME}_endpt', project=PROJECT_ID, location=LOCATION)\n",
    "\n",
    "model.deploy(\n",
    "        endpoint=endpoint,\n",
    "        traffic_percentage = 100,\n",
    "        machine_type ='n1-highcpu-2')\n",
    "\n",
    "model.wait()\n",
    "print(model.resource_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3e2a4e",
   "metadata": {},
   "source": [
    "## Endpoint Prediction\n",
    "Predict if the visitors will buy on return of visit using the API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37acc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile default-pred.json\n",
    "{\"instances\": [{\"age\" :39,\"job\":\"self-employed\",\"marital\":\"divorced\",\"education\":\"high.school\",\"defaulted\":\"no\",\"housing\": \"no\",\n",
    "                \"loan\":\"no\",\"contact\":\"cellular\",\"month\":\"sep\",\"day_of_week\":tue,\"duration\":261,\"campaign\":1,\"pdays\":3,\"previous\":1,\n",
    "                \"poutcome\":\"success\",\"emp_var_rate\":-3.4,\"cons_price_idx\":92.379,\"cons_conf_idx\":-29.8,\"euribor3m\":0.788,\"nr_employed\":5018.5}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba42285e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENDPOINT_ID=endpoint.resource_name\n",
    "\n",
    "!curl \\\n",
    "-X POST \\\n",
    "-H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
    "-H \"Content-Type: application/json\" \\\n",
    "https://us-central1-prediction-aiplatform.googleapis.com/v1alpha1/$ENDPOINT_ID:predict \\\n",
    "-d \"@default-pred.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0bddbc",
   "metadata": {},
   "source": [
    "# Creating a Vertex AI Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceec068e",
   "metadata": {},
   "source": [
    "Now that we have manually created a model and exported it to a vertex endpoint, we can create a pipeline which can be retrained adding MLOps capabilities for a production grade ML workflow. See the bqpipeline_demo.ipynb Notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43d915b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Additional resources: \n",
    "#https://www.qwiklabs.com/focuses/1794?parent=catalog\n",
    "#https://cloud.google.com/bigquery-ml/docs/exporting-models?_ga=2.59990958.-2027684164.1621380090\n",
    "#https://docs.google.com/document/d/1wre9hLVx-H8syG-806UPWGJbDVGieIM5VvFKi8lbGtw/edit\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "managed-notebooks.m78",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/managed-notebooks:m78"
  },
  "kernelspec": {
   "display_name": "Python (Local)",
   "language": "python",
   "name": "local-base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
